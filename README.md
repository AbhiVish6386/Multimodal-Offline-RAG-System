#  NexusMind â€” Unified Offline Multimodal RAG System

> **A fully offline AI assistant** that unifies Text, Image, and Audio understanding through Retrieval-Augmented Generation (RAG).
> Built for enterprise environments needing **data privacy**, **citation transparency**, and **GPU-optimized performance** â€” all without internet.

---

##  Overview

**NexusMind** is a **locally hosted AI system** that performs intelligent retrieval and reasoning over multiple content types â€” including **PDFs, DOCX files, images, and audio** â€” using a combination of **FAISS**, **SentenceTransformer**, and **Llama.cpp**.

It provides:

*  **100% Offline Functionality** (no APIs, no cloud)
*  **Multimodal Understanding** (Text, OCR, Speech)
*  **Citation Transparency** (source-linked answers)
*  **Hardware Adaptive Execution** (CPU/GPU auto-detect)
*  **Single-Page UI** â€” *All controls visible upfront; zero abstraction.*
*  **Adaptive Model Loading:** Detects hardware to choose between Llama-1B, 3B, or 8B models automatically.
*  **Transparent Results:** Every answer is citation-linked to its source.
*  **Future Ready:** Upcoming support for **video input (frame + audio extraction)**.

---

##  Demonstration Video

 Watch full working demo on YouTube: *https://youtu.be/brJ8DDGZnLM*

---

## ğŸ§± System Architecture (Summary)

```
User Input
   â†“
Data Ingestion (PDF / DOCX / Image / Audio)
   â†“
Preprocessing & Normalization
   â†“
Embedding Generation (SentenceTransformer)
   â†“
Vector Indexing (FAISS)
   â†“
Query & Context Retrieval (Top-K Matching)
   â†“
Local Inference (Llama.cpp)
   â†“
Output + Citations (Flask UI)
```

---

##  Project Structure

```
NexusMind/
â”‚
â”œâ”€â”€ app.py                 # Flask backend server
â”œâ”€â”€ ingest.py              # Data extraction (PDF, DOCX, OCR, Audio)
â”œâ”€â”€ embed_index.py         # Embedding generation & FAISS indexing
â”œâ”€â”€ query_rag.py           # RAG query + response pipeline
â”œâ”€â”€ hardware_check.py      # System hardware detection
â”œâ”€â”€ templates/             # Frontend HTML files
â”œâ”€â”€ static/                # CSS / JS / Icons / Animations
â”œâ”€â”€ models/                # Local Llama models (1B / 3B / 8B)
â”œâ”€â”€ uploads/               # Uploaded files
â”œâ”€â”€ faiss_index.bin        # Vector index storage
â”œâ”€â”€ metadata.pkl           # Metadata for chunk references
â””â”€â”€ requirements.txt       # Python dependencies
```

---

## ğŸ–¥ï¸ System Requirements

| Component   | Minimum                | Recommended                                       |
| ----------- | ---------------------- | ------------------------------------------------- |
| **CPU**     | Intel i5 10th Gen      | Intel i9-14900HX                                  |
| **GPU**     | GTX 1650 (4GB)         | RTX 4060 / 5060 (8GB)                             |
| **RAM**     | 8 GB                   | 24 GB DDR5                                        |
| **Storage** | 10 GB free             | 1 TB NVMe SSD                                     |
| **OS**      | Windows 10/11 (64-bit) | Windows 11 Pro                                    |
| **Python**  | 3.9 â€“ **3.10 only** â—  | *Do not use 3.11+* (FAISS-GPU/CPU not compatible) |

---

##  Software Dependencies

Install all dependencies from `requirements.txt` using:

```bash
pip install -r requirements.txt
```

---

##  Running the Project

**Step 1: Initialize the environment**

```bash
python -m venv venv
venv\Scripts\activate
```

**Step 2: Install dependencies**

```bash
pip install -r requirements.txt
```

**Step 3: Start the application**

```bash
python app.py
```

Then open your browser and go to:
 **[http://localhost:5000](http://localhost:5000)**

---
## Model Handling & Downloads

Default model path: `models/llama-3-8b.gguf`  
Modify configuration in `hardware_check.py` based on system specs.

| Model | Description | Type | Download Link |
|--------|--------------|------|---------------|
| **Llama-1B** | Lightweight CPU model for low-end systems | ğŸ§  CPU-Friendly | [Download (1B GGUF)](https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF) |
| **Llama-3B** | Balanced model for CPU + mid GPU usage | âš™ï¸ Balanced | [Download (3B GGUF)](https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF) |
| **Llama-8B** | High-performance GPU model (used in NexusMind) | âš¡ GPU Optimized | [Download (8B GGUF)](https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF) |
| **all-MiniLM-L6-v2** | Text Embedding model (used for FAISS indexing) | ğŸ” SentenceTransformer | [Download (Hugging Face)](https://huggingface.co/leliuga/all-MiniLM-L6-v2-GGUF) |
 


> **Important** Use Python **â‰¤ 3.10** for FAISS-GPU support.
>  **Select the version during downloding Q4_K_M.**

---

## Technical Highlights

| Function             | Technology Used                            |
| -------------------- | ------------------------------------------ |
| Data Extraction      | PyMuPDF, python-docx, Pytesseract, Whisper |
| Embedding Generation | SentenceTransformer (MiniLM)               |
| Vector Storage       | FAISS                                      |
| Context Retrieval    | Top-K Similarity Search                    |
| Model Inference      | Llama.cpp (Local)                          |
| Frontend             | HTML, CSS, JavaScript                      |
| Backend              | Flask                                      |
| Monitoring           | psutil, pynvml                             |

---

##  Limitations

* Requires **GPU** for fast inference; CPU mode is slower.
* **Whisper** accuracy depends on audio quality.
* **OCR** accuracy may drop for low-resolution images.
* **FAISS-GPU** currently supports **Python â‰¤ 3.10** only.

---

## Future Enhancements

*  **Video ingestion support** (frame + speech extraction)
*  **Multi-user collaboration mode**
*  **Hybrid cloud integration** for distributed inference
*  **Local database embedding refresh**
*  **Fine-tuned domain models** (medical, legal, academic)

---

##  Conclusion

NexusMind proves that **AI doesnâ€™t need the internet to be intelligent**.
It delivers **multimodal understanding**, **citation-based transparency**, and **fully local computation** â€” aligning with mission **ethical and responsible AI**.

>  *Designed for performance. Built for privacy. Inspired by intelligence.*

---

## ğŸ‘¨â€ğŸ’» Author

**Abhishek Kumar Vishwakarma**
Department of Computer Science (AI & DS)
Shri Ramswaroop Memorial University, Barabanki
**Guide:** Rohit Sir
**Submission:** IBM Academic Collaboration Program â€” *10 November 2025*
